{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from torch import nn\n",
    "import signatory\n",
    "\n",
    "from lib.augmentations import augment_path_and_compute_signatures,AddTime,LeadLag\n",
    "from lib.datasets import get_stock_price\n",
    "from lib.utils import sample_indices, to_numpy, set_seed, regression_on_linear_functional, predict\n",
    "from lib.test_metrics import get_standard_test_metrics\n",
    "from lib.network.arfnn import ArFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigcwgan = {\n",
    "    \"device\" : \"cuda:0\",\n",
    "    \"epoch\" : 1000,\n",
    "    \"batch_size\" : 200,\n",
    "    \"window_size_past\" : 3,\n",
    "    \"window_size_future\" : 3,\n",
    "}\n",
    "data_config = {\n",
    "    \"ticker\" : \"^GSPC\",\n",
    "    \"interval\" : \"1d\",\n",
    "    \"column\" : 0,  \n",
    "    \"window_size\" : 30,\n",
    "    \"dir\" : \"datasets\",\n",
    "    \"subdir\" : \"stock\"\n",
    "}\n",
    "sig_config = {\n",
    "    \"depth\" : 2,\n",
    "    \"augmentations\" : tuple([LeadLag()]),\n",
    "}\n",
    "arfnn_config = {\n",
    "    \"hidden_dims\" : 3 * (50,),\n",
    "}\n",
    "\n",
    "set_seed(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolled data for training, shape torch.Size([1480, 30, 1])\n",
      "Total data:  [1480, 30, 1]\n"
     ]
    }
   ],
   "source": [
    "x_real_rolled = get_stock_price(data_config)\n",
    "x_real_rolled = x_real_rolled.to(sigcwgan['device'])\n",
    "print('Total data: ', list(x_real_rolled.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SigW1Loss()]\n"
     ]
    }
   ],
   "source": [
    "test_metrics_test = get_standard_test_metrics(x_real_rolled)\n",
    "\n",
    "print(test_metrics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigcwgan_loss(sig_pred: torch.Tensor, sig_fake_conditional_expectation: torch.Tensor):\n",
    "    return torch.norm(sig_pred - sig_fake_conditional_expectation, p=2, dim=1).mean()\n",
    "\n",
    "def calibrate_sigw1_metric(config, x_future, x_past):\n",
    "    sigs_past = config.compute_sig_past(x_past)\n",
    "    sigs_future = config.compute_sig_future(x_future)\n",
    "    assert sigs_past.size(0) == sigs_future.size(0)\n",
    "    X, Y = to_numpy(sigs_past), to_numpy(sigs_future)\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X, Y)\n",
    "    sigs_pred = torch.from_numpy(lm.predict(X)).float().to(x_future.device)\n",
    "    return sigs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigCWGAN(nn.Module):\n",
    "    def __init__(self, G, x_real: torch.Tensor, test_metrics, sigconfig: dict, **kargs):\n",
    "        super(SigCWGAN, self).__init__()\n",
    "        self.G = G\n",
    "        self.p, self.q = kargs[\"window_size_past\"], kargs[\"window_size_future\"]\n",
    "        self.epoch = kargs['epoch']\n",
    "        self.device = kargs['device']\n",
    "\n",
    "        self.x_real = x_real\n",
    "        self.dim = self.latent_dim = x_real.shape[-1]\n",
    "\n",
    "        self.losses_history = defaultdict(list)\n",
    "        self.test_metrics = test_metrics\n",
    "        self.sig_config = sigconfig\n",
    "        self.batch_size = kargs[\"batch_size\"]\n",
    "\n",
    "        self.x_past = x_real[:, :self.p]\n",
    "        x_future = x_real[:, self.p:]\n",
    "\n",
    "        linear_functional = regression_on_linear_functional(x_future=x_future,x_past=self.x_past,sig_config=self.sig_config)\n",
    "        sig_past = augment_path_and_compute_signatures(self.x_past,self.sig_config[\"depth\"])\n",
    "        \n",
    "        self.sigs_pred = predict(linear_functional=linear_functional,sig_past=sig_past)\n",
    "\n",
    "        self.G_optimizer = torch.optim.Adam(self.G.parameters(), lr=1e-2)\n",
    "        self.G_scheduler = torch.optim.lr_scheduler.StepLR(self.G_optimizer, step_size=100, gamma=0.9)\n",
    "\n",
    "    def sample_batch(self, ):\n",
    "        random_indices = sample_indices(self.sigs_pred.shape[0], self.batch_size)  # sample indices\n",
    "        # sample the least squares signature and the log-rtn condition\n",
    "        sigs_pred = self.sigs_pred[random_indices].clone().to(self.device)\n",
    "        x_past = self.x_past[random_indices].clone().to(self.device)\n",
    "        return sigs_pred, x_past\n",
    "\n",
    "    def step(self):\n",
    "        self.G.train()\n",
    "        self.G_optimizer.zero_grad()  # empty 'cache' of gradients\n",
    "        sigs_pred, x_past = self.sample_batch()\n",
    "\n",
    "        # Compute S(x_fake)\n",
    "        # sigs_fake_ce, x_fake = sample_sig_fake(self.G, self.q, self.sig_config, x_past)\n",
    "        x_past = x_past.repeat(self.sig_config[\"batch_size\"], 1, 1).requires_grad_()\n",
    "        x_fake = self.G.sample(self.q, x_past)\n",
    "        sigs_fake_future = augment_path_and_compute_signatures(x_fake,self.sig_config[\"augmentations\"])\n",
    "        sigs_fake_ce = sigs_fake_future.reshape(self.sig_config[\"batch_size\"], x_past.size(0), -1).mean(0)\n",
    "        \n",
    "        loss = sigcwgan_loss(sigs_pred, sigs_fake_ce)\n",
    "        loss.backward()\n",
    "        total_norm = torch.nn.utils.clip_grad_norm_(self.G.parameters(), 10)\n",
    "        self.losses_history['loss'].append(loss.item())\n",
    "        self.losses_history['total_norm'].append(total_norm)\n",
    "        self.G_optimizer.step()\n",
    "        self.G_scheduler.step()  # decaying learning rate slowly.\n",
    "        self.evaluate(x_fake)\n",
    "\n",
    "    def evaluate(self, x_fake):\n",
    "        for test_metric in self.test_metrics:\n",
    "            with torch.no_grad():\n",
    "                test_metric(x_fake[:100])\n",
    "            self.losses_history[test_metric.name].append(\n",
    "                to_numpy(self.test_metrics.loss_componentwise)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_dims': (50, 50, 50), 'input_dim': 3, 'output_dim': 1, 'latent_dim': 1}\n"
     ]
    }
   ],
   "source": [
    "x_real_dim = x_real_rolled.shape[-1]\n",
    "input_dim = sigcwgan[\"window_size_past\"]*x_real_dim\n",
    "arfnn_config.update(input_dim=input_dim)\n",
    "arfnn_config.update(output_dim=x_real_dim)\n",
    "arfnn_config.update(latent_dim=x_real_dim)\n",
    "print(arfnn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AR_FNN = ArFNN(input_dim=arfnn_config[\"input_dim\"],output_dim=arfnn_config[\"output_dim\"],hidden_dims=arfnn_config[\"hidden_dims\"],latent_dim=arfnn_config[\"latent_dim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sigcwgan \u001b[38;5;241m=\u001b[39m \u001b[43mSigCWGAN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAR_FNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_real\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_real_rolled\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_metrics_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43msigconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msig_config\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msigcwgan\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36mSigCWGAN.__init__\u001b[0;34m(self, G, x_real, test_metrics, sigconfig, **kargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_past \u001b[38;5;241m=\u001b[39m x_real[:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp]\n\u001b[1;32m     18\u001b[0m x_future \u001b[38;5;241m=\u001b[39m x_real[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp:]\n\u001b[0;32m---> 20\u001b[0m linear_functional \u001b[38;5;241m=\u001b[39m \u001b[43mregression_on_linear_functional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_future\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_future\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_past\u001b[49m\u001b[43m,\u001b[49m\u001b[43msig_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msig_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m sig_past \u001b[38;5;241m=\u001b[39m augment_path_and_compute_signatures(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_past,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msig_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigs_pred \u001b[38;5;241m=\u001b[39m predict(linear_functional\u001b[38;5;241m=\u001b[39mlinear_functional,sig_past\u001b[38;5;241m=\u001b[39msig_past)\n",
      "File \u001b[0;32m~/Desktop/mlgroup/Signature GAN/lib/utils.py:36\u001b[0m, in \u001b[0;36mregression_on_linear_functional\u001b[0;34m(x_future, x_past, sig_config)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregression_on_linear_functional\u001b[39m(x_future, x_past, sig_config):\n\u001b[0;32m---> 36\u001b[0m     sig_future \u001b[38;5;241m=\u001b[39m \u001b[43maugment_path_and_compute_signatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_future\u001b[49m\u001b[43m,\u001b[49m\u001b[43msig_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdepth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     sig_past \u001b[38;5;241m=\u001b[39m augment_path_and_compute_signatures(x_past,sig_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     38\u001b[0m     linear_functional \u001b[38;5;241m=\u001b[39m LinearRegression()\n",
      "File \u001b[0;32m~/Desktop/mlgroup/Signature GAN/lib/augmentations.py:79\u001b[0m, in \u001b[0;36maugment_path_and_compute_signatures\u001b[0;34m(x, config)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maugment_path_and_compute_signatures\u001b[39m(x: torch\u001b[38;5;241m.\u001b[39mTensor, config: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 79\u001b[0m     y \u001b[38;5;241m=\u001b[39m apply_augmentations(x, \u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maugmentations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m signatory\u001b[38;5;241m.\u001b[39msignature(y, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m\"\u001b[39m], basepoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "sigcwgan = SigCWGAN(G=AR_FNN,x_real=x_real_rolled,test_metrics=test_metrics_test,sigconfig=sig_config,**sigcwgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siggan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
